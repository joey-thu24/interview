from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import json
import re

from core.data.real_questions import get_real_questions
import random

class InterviewerAgent:
    def __init__(self, llm):
        self.llm = llm

    def generate_question(self, topic, difficulty="ä¸­ç­‰", history=[], jd_text=None):
        """
        ç”Ÿæˆé¢è¯•é¢˜ç›®
        :param jd_text: å¯é€‰ï¼ŒJD å†…å®¹ã€‚å¦‚æœå­˜åœ¨ï¼Œåˆ™åŸºäº JD å‡ºé¢˜ã€‚
        """
        
        # 1. JD æ¨¡å¼ (ä¼˜å…ˆ)
        if jd_text:
            return self._generate_from_jd(jd_text, difficulty, history)
            
        # 2. çœŸé¢˜åº“æ¨¡å¼ (æ¦‚ç‡è§¦å‘ï¼Œä¾‹å¦‚ 70% æ¦‚ç‡æŠ½çœŸé¢˜ï¼Œå¢åŠ æƒŠå–œæ„Ÿ)
        # æ£€æŸ¥å†å²æ˜¯å¦å·²ç»é—®è¿‡ï¼Œé¿å…é‡å¤
        asked_questions = [h['content'] for h in history if h['role']=='assistant']
        real_candidates = get_real_questions(topic)
        # è¿‡æ»¤æ‰å·²ç»é—®è¿‡çš„ï¼ˆç®€å•çš„å­—ç¬¦ä¸²åŒ…å«åŒ¹é…ï¼‰
        available_real = [q for q in real_candidates if q['question'] not in str(asked_questions)]
        
        if available_real and random.random() < 0.7:
            # æŠ½é€‰çœŸé¢˜
            selected = random.choice(available_real)
            prefix = f"ã€ğŸš€ {selected['company']} {selected['year']} çœŸé¢˜ã€‘"
            return f"{prefix} {selected['question']}"
            
        # 3. LLM ç”Ÿæˆæ¨¡å¼ (å…œåº•)
        system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„{topic}æŠ€æœ¯é¢è¯•å®˜ã€‚
è¯·æ ¹æ®å€™é€‰äººçš„é¢è¯•å†å²ï¼Œæå‡ºä¸€ä¸ªæ–°çš„ã€æœ‰æŒ‘æˆ˜æ€§çš„é¢è¯•é¢˜ã€‚
éš¾åº¦ç­‰çº§ï¼š{difficulty}ã€‚

è¯·åªè¾“å‡ºé—®é¢˜æœ¬èº«ï¼Œä¸è¦åŒ…å«ä»»ä½•å¯’æš„ã€‚
å¦‚æœå†å²è®°å½•ä¸­å·²ç»æœ‰äº†ç±»ä¼¼é—®é¢˜ï¼Œè¯·æ¢ä¸€ä¸ªè§’åº¦æˆ–æ¢ä¸€ä¸ªçŸ¥è¯†ç‚¹ã€‚
"""
        # å°†å†å²å¯¹è¯æ•´ç†ä¸º context string
        # history items are dicts with 'role' and 'content'
        history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in history[-6:]]) if history else "æ— "

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("user", f"å†å²å¯¹è¯ï¼š\n{history_text}\n\nè¯·å‡ºé¢˜ï¼š")
        ])
        
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke({"topic": topic, "difficulty": difficulty})

    def _generate_from_jd(self, jd_text, difficulty, history):
        """
        åŸºäº JD ç”Ÿæˆå®šåˆ¶é—®é¢˜
        """
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸¥å‰çš„é¢è¯•å®˜ã€‚ä½ æ‰‹é‡Œæœ‰ä¸€ä»½è¯¥èŒä½çš„ JDï¼ˆèŒä½æè¿°ï¼‰ã€‚
è¯·æ ¹æ® JD ä¸­çš„æ ¸å¿ƒè¦æ±‚ï¼ˆå…³é”®æŠ€æœ¯æ ˆã€ä¸šåŠ¡åœºæ™¯ã€åŠ åˆ†é¡¹ï¼‰ï¼Œå‘å€™é€‰äººæå‡ºé¢è¯•é—®é¢˜ã€‚

JD å†…å®¹ï¼š
{jd_text}

éš¾åº¦ç­‰çº§ï¼š{difficulty}ã€‚
è¦æ±‚ï¼šåªè¾“å‡ºé—®é¢˜æœ¬èº«ã€‚é—®é¢˜å¿…é¡»ä¸ JD ç´§å¯†ç›¸å…³ï¼Œè€ƒå¯Ÿå€™é€‰äººæ˜¯å¦çœŸçš„åŒ¹é…è¯¥å²—ä½ã€‚
"""
        history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in history[-6:]]) if history else "æ— "
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("user", f"å†å²å¯¹è¯ï¼š\n{history_text}\n\nè¯·åŸºäº JD å‡ºé¢˜ï¼š")
        ])
        
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke({"jd_text": jd_text, "difficulty": difficulty})


    def generate_final_report(self, history):
        """
        é¢è¯•ç»“æŸåç”Ÿæˆç»¼åˆæŠ¥å‘Š
        """
        system_prompt = """ä½ æ˜¯ä¸€ä½é¢è¯•å®˜ã€‚é¢è¯•å·²ç»“æŸï¼Œè¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†å²ï¼Œç»™å‡ºä¸€ä»½é¢è¯•æ€»ç»“æŠ¥å‘Šã€‚
        
è¯·è¾“å‡º JSON æ ¼å¼ï¼š
- "total_score": 0-100 æ€»åˆ†
- "summary": æ€»ä½“è¡¨ç°è¯„ä»·
- "strengths": [äº®ç‚¹1, äº®ç‚¹2]
- "weaknesses": [ä¸è¶³1, ä¸è¶³2]
- "suggestions": [æ”¹è¿›å»ºè®®1, å»ºè®®2]
"""
        # è½¬æ¢å†å²è®°å½•ä¸ºæ–‡æœ¬
        history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in history])
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("user", f"é¢è¯•è®°å½•ï¼š\n{history_text}\n\nè¯·ç”ŸæˆæŠ¥å‘Šã€‚")
        ])
        
        chain = prompt | self.llm | StrOutputParser()
        result = chain.invoke({})
        
        import json
        import re
        try:
            match = re.search(r"\{[\s\S]*\}", result.strip())
            clean = match.group(0) if match else result
            return json.loads(clean)
        except:
            return {"summary": "æŠ¥å‘Šç”Ÿæˆå¤±è´¥", "error": result}

    def evaluate_response(self, topic, question, user_answer):
        """
        è¯„ä»·ç”¨æˆ·çš„å›ç­”
        """
        system_prompt = """ä½ æ˜¯ä¸€ä½å…¬æ­£çš„é¢è¯•å®˜ã€‚è¯·è¯„ä»·å€™é€‰äººå¯¹äºé—®é¢˜ "{question}" çš„å›ç­”ã€‚
å›ç­”å†…å®¹ï¼š"{user_answer}"

è¯·è¾“å‡ºä¸€æ®µ JSONï¼ŒåŒ…å«ï¼š
- "score": 0-100 çš„è¯„åˆ†
- "feedback": ç®€çŸ­çš„è¯„ä»·ï¼ˆæŒ‡å‡ºäº®ç‚¹å’Œä¸è¶³ï¼‰
- "reference": å‚è€ƒç­”æ¡ˆè¦ç‚¹
- "follow_up": å¦‚æœå›ç­”è¿˜å¯ä»¥ï¼Œå¯ä»¥ç»™å‡ºä¸€ä¸ªè¿½é—®é—®é¢˜ï¼›å¦‚æœå›ç­”å¤ªå·®ï¼Œåˆ™ä¸ºç©ºã€‚
"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("user", "è¯·è¯„ä»·ã€‚")
        ])
        
        # å®é™…é¡¹ç›®ä¸­è¿™é‡Œåº”è¯¥ç”¨ JsonOutputParserï¼Œä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿å…ˆç”¨ Strå¤„ç†
        chain = prompt | self.llm | StrOutputParser()
        result = chain.invoke({"topic": topic, "question": question, "user_answer": user_answer})
        
        # ç®€å•æ¸…æ´—
        try:
            # å°è¯•æå– JSON éƒ¨åˆ†
            match = re.search(r"\{[\s\S]*\}", result.strip())
            if match:
                clean_response = match.group(0)
            else:
                clean_response = result.replace("```json", "").replace("```", "").strip()
            
            return json.loads(clean_response)
        except Exception as e:
            print(f"JSON Parse Error in Interviewer: {e}")
            return {
                "score": 60,
                "feedback": "è§£æè¯„åˆ†å¤±è´¥ï¼Œä½†ä½ çš„å›ç­”å·²è¢«è®°å½•ã€‚",
                "reference": "æ— ",
                "follow_up": None,
                "raw": result
            }
